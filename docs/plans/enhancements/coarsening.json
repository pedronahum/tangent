{
  "project": {
    "name": "Coarsening Optimization for Tangent",
    "description": "Implementation of coarsening optimization from OOPSLA 2021 paper - hybrid symbolic/algorithmic differentiation",
    "paper_reference": "Xipeng Shen et al. 'Coarsening Optimization for Differentiable Programming' OOPSLA 2021",
    "expected_impact": {
      "speedup": "2-27 on differentiation (from paper)",
      "memory_reduction": "40-70% (fewer intermediate allocations)",
      "key_benefit": "Can eliminate primal computation when only gradients needed"
    },
    "key_innovations": [
      "-calculus: enables symbolic differentiation across control flow",
      "Reuse-aware SOI identification: balances coarsening scope vs computation reuse",
      "Hybrid approach: combines symbolic differentiation (compile-time) with AD (runtime)"
    ]
  },
  "phases": [
    {
      "phase": 1,
      "name": "-Calculus Foundation",
      "objective": "Implement -calculus to enable symbolic differentiation across control flow",
      "expected_impact": "Enables coarsening across loops and branches (vs only straight-line code)",
      "duration_estimate": "3-4 weeks",
      "complexity": "High (novel contribution from paper)",
      "background": {
        "problem": "Symbolic differentiation traditionally limited to straight-line code without control flow",
        "solution": "-calculus: extends SSA with symbolic reasoning about -functions",
        "key_insight": "-functions (from SSA) can be treated symbolically and differentiated using special rules",
        "paper_section": "Section 4"
      },
      "tasks": [
        {
          "task_id": "1.1",
          "name": "SSA Conversion for Tangent",
          "file": "tangent/optimizations/ssa.py",
          "description": "Convert Tangent IR to SSA form as foundation for -calculus",
          "paper_reference": "Section 4.1 (Background on SSA)",
          "code": "\"\"\"\\nStatic Single Assignment (SSA) conversion for Tangent.\\n\\nSSA is the foundation for -calculus, ensuring each variable is assigned exactly once.\\n\\\"\\\"\\\"\\n\\nimport ast\\nimport gast\\nfrom typing import Dict, List, Set, Tuple\\nfrom collections import defaultdict\\n\\n\\nclass PhiFunction:\\n    \\\"\\\"\\\"\\n    Represents a -function in SSA.\\n    \\n    (a, b) means: choose a if came from first branch, b if came from second branch.\\n    \\n    Example:\\n        if condition:\\n            x = 1\\n        else:\\n            x = 2\\n        y = (x_1, x_2)  # y gets x_1 or x_2 depending on branch taken\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self, var_name: str, alternatives: List[Tuple[str, str]]):\\n        \\\"\\\"\\\"\\n        Args:\\n            var_name: The variable being defined by this -function\\n            alternatives: [(value1, source_block1), (value2, source_block2), ...]\\n        \\\"\\\"\\\"\\n        self.var_name = var_name\\n        self.alternatives = alternatives\\n        self.phi_type = None  # Will be 'entry', 'exit', or 'normal'\\n    \\n    def __repr__(self):\\n        alt_str = ', '.join(f'{val}' for val, _ in self.alternatives)\\n        return f'({alt_str})'\\n\\n\\nclass LoopPhiFunctions:\\n    \\\"\\\"\\\"\\n    Special -functions for loops.\\n    \\n    Every loop has:\\n    - Entry -functions: _L(init_value, loop_value)\\n    - Exit -functions: _L'(init_value_if_not_entered, final_value_if_entered)\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self, loop_id: str):\\n        self.loop_id = loop_id\\n        self.entry_phis = {}  # var_name -> PhiFunction\\n        self.exit_phis = {}   # var_name -> PhiFunction\\n    \\n    def add_entry_phi(self, var_name: str, init_val: str, loop_val: str):\\n        \\\"\\\"\\\"Add entry -function: var = _L(init_val, loop_val).\\\"\\\"\\\"\\n        phi = PhiFunction(var_name, [(init_val, 'init'), (loop_val, 'loop')])\\n        phi.phi_type = 'entry'\\n        self.entry_phis[var_name] = phi\\n    \\n    def add_exit_phi(self, var_name: str, no_entry_val: str, exit_val: str):\\n        \\\"\\\"\\\"Add exit -function: var = _L'(no_entry_val, exit_val).\\\"\\\"\\\"\\n        phi = PhiFunction(var_name, [(no_entry_val, 'no_entry'), (exit_val, 'exit')])\\n        phi.phi_type = 'exit'\\n        self.exit_phis[var_name] = phi\\n\\n\\nclass SSAConverter:\\n    \\\"\\\"\\\"\\n    Convert Python AST to SSA form.\\n    \\n    Main steps:\\n    1. Build Control Flow Graph (CFG)\\n    2. Compute dominance frontiers\\n    3. Insert -functions at merge points\\n    4. Rename variables to ensure single assignment\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.var_versions = defaultdict(int)  # var_name -> current_version\\n        self.var_stacks = defaultdict(list)   # var_name -> [version_stack]\\n        self.phi_functions = {}                # block_id -> {var: PhiFunction}\\n        self.loop_phis = {}                    # loop_id -> LoopPhiFunctions\\n    \\n    def convert(self, func_ast):\\n        \\\"\\\"\\\"\\n        Convert function to SSA form.\\n        \\n        Args:\\n            func_ast: Function AST node\\n        \\n        Returns:\\n            SSA form with -functions inserted\\n        \\\"\\\"\\\"\\n        # Step 1: Build CFG\\n        cfg = self._build_cfg(func_ast)\\n        \\n        # Step 2: Compute dominance frontiers (where to place -functions)\\n        dom_frontier = self._compute_dominance_frontier(cfg)\\n        \\n        # Step 3: Insert -functions\\n        self._insert_phi_functions(cfg, dom_frontier)\\n        \\n        # Step 4: Rename variables\\n        self._rename_variables(cfg)\\n        \\n        return func_ast\\n    \\n    def _build_cfg(self, func_ast):\\n        \\\"\\\"\\\"\\n        Build Control Flow Graph.\\n        \\n        Returns:\\n            CFG with blocks and edges\\n        \\\"\\\"\\\"\\n        cfg = ControlFlowGraph()\\n        \\n        # Create basic blocks\\n        current_block = cfg.new_block('entry')\\n        \\n        for stmt in func_ast.body:\\n            if isinstance(stmt, (ast.If, gast.If)):\\n                # Branch creates multiple paths\\n                then_block = cfg.new_block('then')\\n                else_block = cfg.new_block('else')\\n                merge_block = cfg.new_block('merge')\\n                \\n                cfg.add_edge(current_block, then_block)\\n                cfg.add_edge(current_block, else_block)\\n                \\n                # Process branches\\n                self._build_cfg_for_block(stmt.body, then_block, cfg)\\n                self._build_cfg_for_block(stmt.orelse, else_block, cfg)\\n                \\n                cfg.add_edge(then_block, merge_block)\\n                cfg.add_edge(else_block, merge_block)\\n                \\n                current_block = merge_block\\n            \\n            elif isinstance(stmt, (ast.For, gast.For, ast.While, gast.While)):\\n                # Loop creates cycle in CFG\\n                loop_id = f'loop_{id(stmt)}'\\n                \\n                loop_header = cfg.new_block(f'{loop_id}_header')\\n                loop_body = cfg.new_block(f'{loop_id}_body')\\n                loop_exit = cfg.new_block(f'{loop_id}_exit')\\n                \\n                cfg.add_edge(current_block, loop_header)\\n                cfg.add_edge(loop_header, loop_body)\\n                cfg.add_edge(loop_body, loop_header)  # Back edge\\n                cfg.add_edge(loop_header, loop_exit)\\n                \\n                # Mark loop -functions needed\\n                self.loop_phis[loop_id] = LoopPhiFunctions(loop_id)\\n                \\n                current_block = loop_exit\\n            \\n            else:\\n                # Regular statement, add to current block\\n                current_block.add_statement(stmt)\\n        \\n        return cfg\\n    \\n    def _build_cfg_for_block(self, stmts, block, cfg):\\n        \\\"\\\"\\\"Helper to build CFG for a list of statements.\\\"\\\"\\\"\\n        for stmt in stmts:\\n            block.add_statement(stmt)\\n    \\n    def _compute_dominance_frontier(self, cfg):\\n        \\\"\\\"\\\"\\n        Compute dominance frontier for each block.\\n        \\n        Dominance frontier of block B is the set of blocks where:\\n        - B dominates a predecessor of the block\\n        - B does not strictly dominate the block itself\\n        \\n        This tells us where to place -functions.\\n        \\\"\\\"\\\"\\n        # Compute dominators first\\n        dominators = self._compute_dominators(cfg)\\n        \\n        # Compute dominance frontier\\n        dom_frontier = defaultdict(set)\\n        \\n        for block in cfg.blocks:\\n            if len(block.predecessors) >= 2:  # Merge point\\n                for pred in block.predecessors:\\n                    runner = pred\\n                    while runner and runner not in dominators[block]:\\n                        dom_frontier[runner].add(block)\\n                        runner = dominators[runner]\\n        \\n        return dom_frontier\\n    \\n    def _compute_dominators(self, cfg):\\n        \\\"\\\"\\\"\\n        Compute immediate dominators using iterative algorithm.\\n        \\n        Returns:\\n            Dict mapping each block to its immediate dominator\\n        \\\"\\\"\\\"\\n        # Standard dominance algorithm (not shown for brevity)\\n        # Returns: block -> immediate_dominator\\n        dominators = {}\\n        \\n        # Initialize\\n        entry = cfg.entry_block\\n        dominators[entry] = entry\\n        \\n        changed = True\\n        while changed:\\n            changed = False\\n            for block in cfg.blocks:\\n                if block == entry:\\n                    continue\\n                \\n                # New dominator = intersection of predecessors' dominators\\n                new_dom = self._intersect_dominators(\\n                    [dominators.get(pred) for pred in block.predecessors]\\n                )\\n                \\n                if dominators.get(block) != new_dom:\\n                    dominators[block] = new_dom\\n                    changed = True\\n        \\n        return dominators\\n    \\n    def _intersect_dominators(self, dom_list):\\n        \\\"\\\"\\\"Helper to find common dominator.\\\"\\\"\\\"\\n        # Simplified implementation\\n        return dom_list[0] if dom_list else None\\n    \\n    def _insert_phi_functions(self, cfg, dom_frontier):\\n        \\\"\\\"\\\"\\n        Insert -functions at dominance frontiers.\\n        \\n        For each variable and each block in its dominance frontier,\\n        insert (v1, v2, ..., vn) where n = number of predecessors.\\n        \\\"\\\"\\\"\\n        # Find all variables that are assigned\\n        assigned_vars = set()\\n        for block in cfg.blocks:\\n            for stmt in block.statements:\\n                if isinstance(stmt, (ast.Assign, gast.Assign)):\\n                    for target in stmt.targets:\\n                        if isinstance(target, (ast.Name, gast.Name)):\\n                            assigned_vars.add(target.id)\\n        \\n        # For each variable, insert  at dominance frontiers\\n        for var in assigned_vars:\\n            # Find blocks where var is assigned\\n            def_blocks = [\\n                block for block in cfg.blocks\\n                if any(self._assigns_var(stmt, var) for stmt in block.statements)\\n            ]\\n            \\n            # Insert  at dominance frontiers\\n            work_list = def_blocks[:]\\n            while work_list:\\n                block = work_list.pop()\\n                for frontier_block in dom_frontier[block]:\\n                    if frontier_block not in self.phi_functions:\\n                        self.phi_functions[frontier_block] = {}\\n                    \\n                    if var not in self.phi_functions[frontier_block]:\\n                        # Create -function\\n                        num_preds = len(frontier_block.predecessors)\\n                        phi = PhiFunction(\\n                            var,\\n                            [(f'{var}_?', f'pred{i}') for i in range(num_preds)]\\n                        )\\n                        self.phi_functions[frontier_block][var] = phi\\n                        \\n                        # May need more -functions\\n                        if frontier_block not in work_list:\\n                            work_list.append(frontier_block)\\n    \\n    def _assigns_var(self, stmt, var_name):\\n        \\\"\\\"\\\"Check if statement assigns to variable.\\\"\\\"\\\"\\n        if isinstance(stmt, (ast.Assign, gast.Assign)):\\n            for target in stmt.targets:\\n                if isinstance(target, (ast.Name, gast.Name)):\\n                    if target.id == var_name:\\n                        return True\\n        return False\\n    \\n    def _rename_variables(self, cfg):\\n        \\\"\\\"\\\"\\n        Rename variables to ensure single assignment.\\n        \\n        Each assignment creates a new version: x, x_1, x_2, etc.\\n        \\\"\\\"\\\"\\n        # Initialize stacks\\n        for var in self.var_versions.keys():\\n            self.var_stacks[var] = []\\n        \\n        # Rename starting from entry block\\n        self._rename_block(cfg.entry_block, cfg)\\n    \\n    def _rename_block(self, block, cfg):\\n        \\\"\\\"\\\"Recursively rename variables in block and its successors.\\\"\\\"\\\"\\n        # Process -functions first\\n        if block in self.phi_functions:\\n            for var, phi in self.phi_functions[block].items():\\n                # Create new version for  result\\n                new_version = self._new_version(var)\\n                phi.var_name = f'{var}_{new_version}'\\n                self.var_stacks[var].append(new_version)\\n        \\n        # Process statements\\n        for stmt in block.statements:\\n            # Rename uses (RHS)\\n            self._rename_uses(stmt)\\n            \\n            # Rename definitions (LHS)\\n            if isinstance(stmt, (ast.Assign, gast.Assign)):\\n                for target in stmt.targets:\\n                    if isinstance(target, (ast.Name, gast.Name)):\\n                        var = target.id\\n                        new_version = self._new_version(var)\\n                        target.id = f'{var}_{new_version}'\\n                        self.var_stacks[var].append(new_version)\\n        \\n        # Update -functions in successors\\n        for succ in block.successors:\\n            if succ in self.phi_functions:\\n                for var, phi in self.phi_functions[succ].items():\\n                    # Update the alternative corresponding to this predecessor\\n                    if self.var_stacks[var]:\\n                        current_version = self.var_stacks[var][-1]\\n                        # Update phi alternative (implementation detail)\\n        \\n        # Recurse to children in dominator tree\\n        for child in cfg.dom_tree_children(block):\\n            self._rename_block(child, cfg)\\n        \\n        # Pop versions added in this block\\n        # (Implementation detail - manage stack properly)\\n    \\n    def _new_version(self, var_name):\\n        \\\"\\\"\\\"Create new version number for variable.\\\"\\\"\\\"\\n        self.var_versions[var_name] += 1\\n        return self.var_versions[var_name]\\n    \\n    def _rename_uses(self, stmt):\\n        \\\"\\\"\\\"Rename variable uses in a statement.\\\"\\\"\\\"\\n        # Walk AST and rename Name nodes\\n        class UseRenamer(ast.NodeTransformer):\\n            def __init__(self, var_stacks):\\n                self.var_stacks = var_stacks\\n            \\n            def visit_Name(self, node):\\n                if isinstance(node.ctx, (ast.Load, gast.Load)):\\n                    if node.id in self.var_stacks and self.var_stacks[node.id]:\\n                        version = self.var_stacks[node.id][-1]\\n                        node.id = f'{node.id}_{version}'\\n                return node\\n        \\n        renamer = UseRenamer(self.var_stacks)\\n        renamer.visit(stmt)\\n\\n\\nclass ControlFlowGraph:\\n    \\\"\\\"\\\"Simple CFG representation.\\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.blocks = []\\n        self.entry_block = None\\n        self.edges = []\\n    \\n    def new_block(self, name):\\n        \\\"\\\"\\\"Create a new basic block.\\\"\\\"\\\"\\n        block = BasicBlock(name)\\n        self.blocks.append(block)\\n        if self.entry_block is None:\\n            self.entry_block = block\\n        return block\\n    \\n    def add_edge(self, from_block, to_block):\\n        \\\"\\\"\\\"Add edge between blocks.\\\"\\\"\\\"\\n        from_block.successors.append(to_block)\\n        to_block.predecessors.append(from_block)\\n        self.edges.append((from_block, to_block))\\n    \\n    def dom_tree_children(self, block):\\n        \\\"\\\"\\\"Get children in dominator tree.\\\"\\\"\\\"\\n        # Simplified - would need proper dominator tree\\n        return []\\n\\n\\nclass BasicBlock:\\n    \\\"\\\"\\\"A basic block in the CFG.\\\"\\\"\\\"\\n    \\n    def __init__(self, name):\\n        self.name = name\\n        self.statements = []\\n        self.predecessors = []\\n        self.successors = []\\n    \\n    def add_statement(self, stmt):\\n        self.statements.append(stmt)\\n    \\n    def __repr__(self):\\n        return f'Block({self.name})'\\n\\n\\ndef convert_to_ssa(func_ast):\\n    \\\"\\\"\\\"\\n    Convert function to SSA form.\\n    \\n    Args:\\n        func_ast: Function AST\\n    \\n    Returns:\\n        SSA form with -functions\\n    \\\"\\\"\\\"\\n    converter = SSAConverter()\\n    return converter.convert(func_ast)\\n\""
        },
        {
          "task_id": "1.2",
          "name": "-Calculus Core Implementation",
          "file": "tangent/optimizations/phi_calculus.py",
          "description": "Implement -calculus formulae for symbolic reasoning",
          "paper_reference": "Section 4.3 (Formulae in -Calculus), Figure 5",
          "code": "\"\"\"\\n-Calculus implementation for Tangent.\\n\\nEnables symbolic differentiation across control flow by treating\\n-functions symbolically.\\n\\\"\\\"\\\"\\n\\nimport sympy as sp\\nfrom sympy import Symbol, Function, Sum, Product\\nfrom typing import Dict, List, Any\\n\\n\\nclass PhiSymbol(Function):\\n    \\\"\\\"\\\"\\n    Symbolic representation of -function.\\n    \\n    (a, b) represents a choice between a and b based on control flow.\\n    \\\"\\\"\\\"\\n    \\n    @classmethod\\n    def eval(cls, *args):\\n        \\\"\\\"\\\"Evaluation rules for -function.\\\"\\\"\\\"\\n        # Identity formula (F1): (a, a, ..., a) = a\\n        if len(set(args)) == 1:\\n            return args[0]\\n        \\n        return None  # Keep symbolic\\n\\n\\nclass LoopSymbol(Function):\\n    \\\"\\\"\\\"\\n    Symbolic representation of loop: ^n < S >\\n    \\n    Represents: execute S for n iterations\\n    \\\"\\\"\\\"\\n    pass\\n\\n\\nclass PhiCalculus:\\n    \\\"\\\"\\\"\\n    -Calculus formulae from Figure 5 of the paper.\\n    \\n    Fundamental formulae:\\n    F1: Identity - (a, a, ..., a) = a\\n    F2: Distributive - f((a, b)) = (f(a), f(b))\\n    F3: Commutative - (a, b) = (b, a)\\n    F4: Loop entry - _L^(i)(a, s) = a if i=1, else s^(i-1)\\n    F5: Loop exit - _L'(a, b1, ..., bm) = b1_exit if conditions met\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.x, self.y, self.z = sp.symbols('x y z')\\n        self.n = sp.Symbol('n', integer=True, positive=True)\\n    \\n    # ========== FUNDAMENTAL FORMULAE ==========\\n    \\n    def identity_formula(self, expr):\\n        \\\"\\\"\\\"\\n        F1: Identity formula\\n        (a, a, ..., a) = a\\n        \\\"\\\"\\\"\\n        if isinstance(expr, PhiSymbol):\\n            args = expr.args\\n            if len(set(args)) == 1:\\n                return args[0]\\n        return expr\\n    \\n    def distributive_formula(self, func, phi_expr):\\n        \\\"\\\"\\\"\\n        F2: Distributive formula\\n        f((a, b)) = (f(a), f(b))\\n        \\n        This is KEY for symbolic differentiation:\\n        d/dx((a, b)) = (d/dx(a), d/dx(b))\\n        \\\"\\\"\\\"\\n        if isinstance(phi_expr, PhiSymbol):\\n            # Apply func to each alternative\\n            new_args = [func(arg) for arg in phi_expr.args]\\n            return PhiSymbol(*new_args)\\n        \\n        return func(phi_expr)\\n    \\n    def loop_entry_formula(self, loop_id, iteration, init_val, loop_val):\\n        \\\"\\\"\\\"\\n        F4: Loop entry formula\\n        _L^(i)(p, d) = p if i=1, else d^(i-1)\\n        \\n        This says: first iteration uses init value, later iterations use loop value.\\n        \\\"\\\"\\\"\\n        if iteration == 1:\\n            return init_val\\n        else:\\n            # Return value from previous iteration\\n            # In symbolic form, this would be d^(i-1)\\n            return self._previous_iteration_value(loop_val, iteration - 1)\\n    \\n    def loop_exit_formula(self, init_val, loop_vals, conditions):\\n        \\\"\\\"\\\"\\n        F5: Loop exit formula\\n        _L'(a, b1, b2, ..., bm) = b1_exit if:\\n          - All b_i are equal at _L' (except first arg)\\n          - b_i values before loop entry equal first arg\\n        \\n        This is used to eliminate exit -functions.\\n        \\\"\\\"\\\"\\n        # Check if all loop values are the same at exit\\n        if len(set(loop_vals)) == 1:\\n            # All same, return the exit value\\n            return loop_vals[0]\\n        \\n        # Otherwise, keep as \\n        return PhiSymbol(init_val, *loop_vals)\\n    \\n    # ========== COROLLARIES (from paper) ==========\\n    \\n    def corollary_C5_recursive_function(self, f, n_iterations, init_val):\\n        \\\"\\\"\\\"\\n        C5: ^n d = f(_L(p, d)) => d_exit = f^[n](p)\\n        \\n        For recursive function application in loop.\\n        Example: d = f(d) repeated n times => d_exit = f(f(...f(p)))\\n        \\\"\\\"\\\"\\n        result = init_val\\n        for _ in range(n_iterations):\\n            result = f(result)\\n        return result\\n    \\n    def corollary_C6_linear_recurrence(self, a, b, n_iterations, init_val):\\n        \\\"\\\"\\\"\\n        C6: ^n d = a路_L(p, d) + b\\n        => d_exit = a^n路p + b路危(a^i) for i=0 to n-1\\n        \\n        This handles linear recurrences like: d = a*d + b\\n        Example: sum += x in loop becomes closed form\\n        \\\"\\\"\\\"\\n        # Closed form: a^n * p + b * (a^n - 1)/(a - 1)\\n        if a == 1:\\n            # Special case: d = d + b => d_exit = p + n*b\\n            return init_val + n_iterations * b\\n        else:\\n            # General case\\n            geometric_sum = (a**n_iterations - 1) / (a - 1)\\n            return a**n_iterations * init_val + b * geometric_sum\\n    \\n    def corollary_C7_linear_with_array(self, a, b_array, n_iterations, init_val):\\n        \\\"\\\"\\\"\\n        C7: ^n d = a路_L(p, d) + b[i]\\n        => d_exit = a^n路p + 危(a^i路b[n-1-i]) for i=0 to n-1\\n        \\n        This handles: d = a*d + b[i] where b[i] varies by iteration.\\n        Example: sum += array[i] in loop\\n        \\\"\\\"\\\"\\n        result = a**n_iterations * init_val\\n        \\n        # Add weighted sum of array elements\\n        for i in range(n_iterations):\\n            result += a**(n_iterations - 1 - i) * b_array[i]\\n        \\n        return result\\n    \\n    def corollary_C8_multiplicative_array(self, a_array, b_array, n_iterations, init_val):\\n        \\\"\\\"\\\"\\n        C8: ^n d = a[i]路_L(p, d) + b[i]\\n        => d_exit = p路(a[i]) + 危(b[n-1-i]路(a[n-1-j]))\\n        \\n        Most general linear recurrence with varying coefficients.\\n        \\\"\\\"\\\"\\n        # Product of all a[i]\\n        product_a = 1\\n        for i in range(n_iterations):\\n            product_a *= a_array[i]\\n        \\n        result = init_val * product_a\\n        \\n        # Sum term\\n        for i in range(n_iterations):\\n            # Product of a[n-1-j] for j=0 to i-1\\n            partial_product = 1\\n            for j in range(i):\\n                partial_product *= a_array[n_iterations - 1 - j]\\n            \\n            result += b_array[n_iterations - 1 - i] * partial_product\\n        \\n        return result\\n    \\n    def corollary_C9_power_recurrence(self, a, b, n_iterations, init_val):\\n        \\\"\\\"\\\"\\n        C9: ^n d = a路(_L(p, d))^b\\n        => d_exit = a^(b^(n-1))路p^(b^n)\\n        \\n        Handles power recurrences: d = a * d^b\\n        \\\"\\\"\\\"\\n        # This is for exponential growth patterns\\n        return a**(b**(n_iterations - 1)) * init_val**(b**n_iterations)\\n    \\n    # ========== HELPER METHODS ==========\\n    \\n    def _previous_iteration_value(self, expr, iteration):\\n        \\\"\\\"\\\"Get value of expression from previous iteration.\\\"\\\"\\\"\\n        # In symbolic form, annotate with iteration number\\n        return Symbol(f'{expr}_iter_{iteration}')\\n    \\n    def simplify_phi_expression(self, expr):\\n        \\\"\\\"\\\"\\n        Simplify expression containing -functions.\\n        \\n        Applies formulae recursively to eliminate -functions where possible.\\n        \\\"\\\"\\\"\\n        # Apply identity formula\\n        expr = self.identity_formula(expr)\\n        \\n        # Try to simplify recursively\\n        if isinstance(expr, PhiSymbol):\\n            simplified_args = [self.simplify_phi_expression(arg) for arg in expr.args]\\n            return PhiSymbol(*simplified_args)\\n        \\n        return expr\\n    \\n    def differentiate_phi(self, phi_expr, var):\\n        \\\"\\\"\\\"\\n        Differentiate -expression using distributive formula.\\n        \\n        Key insight: d/dx((a, b)) = (d/dx(a), d/dx(b))\\n        \\\"\\\"\\\"\\n        if isinstance(phi_expr, PhiSymbol):\\n            # Apply distributive formula with differentiation\\n            diff_args = [sp.diff(arg, var) for arg in phi_expr.args]\\n            return PhiSymbol(*diff_args)\\n        \\n        return sp.diff(phi_expr, var)\\n\\n\\nclass LoopClosedFormGenerator:\\n    \\\"\\\"\\\"\\n    Generate closed forms for loops using -calculus corollaries.\\n    \\n    This is the key component that transforms loops into symbolic expressions\\n    that can be differentiated.\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.phi_calc = PhiCalculus()\\n    \\n    def analyze_loop_pattern(self, loop_body, loop_var, init_val, n_iterations):\\n        \\\"\\\"\\\"\\n        Analyze loop body to determine which corollary applies.\\n        \\n        Returns:\\n            Closed form expression for loop result\\n        \\\"\\\"\\\"\\n        # Detect pattern in loop body\\n        # Pattern 1: d = d + constant => use C6 with a=1\\n        # Pattern 2: d = d + x*i => use C7\\n        # Pattern 3: d = a*d + b => use C6\\n        # Pattern 4: d = f(d) => use C5\\n        \\n        # This would analyze the AST of loop_body\\n        # For now, return symbolic form\\n        \\n        # Example: if loop is \\\"s = s + x\\\", n times\\n        # Closed form: s_exit = s_init + n*x\\n        \\n        return Symbol(f'{loop_var}_closed_form')\\n    \\n    def generate_closed_form(self, loop_ast, variables):\\n        \\\"\\\"\\\"\\n        Generate closed form for a loop.\\n        \\n        Args:\\n            loop_ast: AST of the loop\\n            variables: Dict of variable values\\n        \\n        Returns:\\n            SymPy expression representing closed form\\n        \\\"\\\"\\\"\\n        # Extract loop pattern\\n        # Apply appropriate corollary\\n        # Return closed form\\n        \\n        # Placeholder - would implement full pattern matching\\n        return Symbol('closed_form_placeholder')\\n\\n\\ndef apply_phi_calculus(ssa_func, target_var):\\n    \\\"\\\"\\\"\\n    Apply -calculus to get closed form for target variable.\\n    \\n    Args:\\n        ssa_func: Function in SSA form (with -functions)\\n        target_var: Variable to compute closed form for\\n    \\n    Returns:\\n        Symbolic expression for target_var\\n    \\\"\\\"\\\"\\n    phi_calc = PhiCalculus()\\n    \\n    # Walk SSA form and apply -calculus formulae\\n    # to eliminate -functions and get closed form\\n    \\n    # Placeholder implementation\\n    return Symbol(target_var)\\n\""
        },
        {
          "task_id": "1.3",
          "name": "-Calculus Tests",
          "file": "tests/test_phi_calculus.py",
          "description": "Tests for -calculus implementation",
          "code": "\"\"\"\\nTests for -calculus.\\n\\\"\\\"\\\"\\nimport unittest\\nimport sympy as sp\\nfrom tangent.optimizations.phi_calculus import (\\n    PhiCalculus,\\n    PhiSymbol,\\n    LoopClosedFormGenerator\\n)\\n\\n\\nclass TestPhiCalculusFormulae(unittest.TestCase):\\n    \\\"\\\"\\\"Test fundamental -calculus formulae.\\\"\\\"\\\"\\n    \\n    def setUp(self):\\n        self.phi_calc = PhiCalculus()\\n        self.x = sp.Symbol('x')\\n        self.y = sp.Symbol('y')\\n    \\n    def test_identity_formula(self):\\n        \\\"\\\"\\\"Test F1: (a, a, a) = a.\\\"\\\"\\\"\\n        phi = PhiSymbol(self.x, self.x, self.x)\\n        result = self.phi_calc.identity_formula(phi)\\n        self.assertEqual(result, self.x)\\n    \\n    def test_distributive_formula(self):\\n        \\\"\\\"\\\"Test F2: f((a, b)) = (f(a), f(b)).\\\"\\\"\\\"\\n        phi = PhiSymbol(self.x, self.y)\\n        \\n        # Apply function (e.g., square)\\n        def square(expr):\\n            return expr ** 2\\n        \\n        result = self.phi_calc.distributive_formula(square, phi)\\n        \\n        # Should be (x虏, y虏)\\n        self.assertIsInstance(result, PhiSymbol)\\n        self.assertEqual(len(result.args), 2)\\n    \\n    def test_loop_entry_formula(self):\\n        \\\"\\\"\\\"Test F4: Loop entry  behavior.\\\"\\\"\\\"\\n        init_val = self.x\\n        loop_val = self.y\\n        \\n        # First iteration should return init value\\n        result_1 = self.phi_calc.loop_entry_formula('L1', 1, init_val, loop_val)\\n        self.assertEqual(result_1, init_val)\\n        \\n        # Later iterations return loop value\\n        result_2 = self.phi_calc.loop_entry_formula('L1', 2, init_val, loop_val)\\n        self.assertIsNotNone(result_2)\\n    \\n    def test_corollary_C6_simple_sum(self):\\n        \\\"\\\"\\\"Test C6: s = s + x in loop => s_exit = s_init + n*x.\\\"\\\"\\\"\\n        a = 1  # Coefficient of s\\n        b = self.x  # What we're adding\\n        n = 5  # Iterations\\n        init = 0  # Initial value\\n        \\n        result = self.phi_calc.corollary_C6_linear_recurrence(a, b, n, init)\\n        \\n        # Should be 0 + 5*x = 5*x\\n        expected = n * self.x\\n        self.assertEqual(sp.simplify(result - expected), 0)\\n    \\n    def test_corollary_C6_geometric(self):\\n        \\\"\\\"\\\"Test C6: d = 2*d + 1 => closed form.\\\"\\\"\\\"\\n        a = 2\\n        b = 1\\n        n = 4\\n        init = 1\\n        \\n        result = self.phi_calc.corollary_C6_linear_recurrence(a, b, n, init)\\n        \\n        # Manual calculation: \\n        # iter 0: 1\\n        # iter 1: 2*1 + 1 = 3\\n        # iter 2: 2*3 + 1 = 7\\n        # iter 3: 2*7 + 1 = 15\\n        # iter 4: 2*15 + 1 = 31\\n        # Formula: 2^4 * 1 + 1*(2^4-1)/(2-1) = 16 + 15 = 31\\n        \\n        self.assertEqual(result, 31)\\n\\n\\nclass TestLoopClosedForms(unittest.TestCase):\\n    \\\"\\\"\\\"Test closed form generation for loops.\\\"\\\"\\\"\\n    \\n    def setUp(self):\\n        self.generator = LoopClosedFormGenerator()\\n    \\n    def test_simple_sum_loop(self):\\n        \\\"\\\"\\\"Test: for i in range(n): s = s + x.\\\"\\\"\\\"\\n        # This would test the full pipeline\\n        # For now, just ensure it doesn't crash\\n        result = self.generator.generate_closed_form(None, {})\\n        self.assertIsNotNone(result)\\n\\n\\nclass TestPhiDifferentiation(unittest.TestCase):\\n    \\\"\\\"\\\"Test differentiation of -expressions.\\\"\\\"\\\"\\n    \\n    def setUp(self):\\n        self.phi_calc = PhiCalculus()\\n        self.x = sp.Symbol('x')\\n        self.y = sp.Symbol('y')\\n    \\n    def test_differentiate_phi(self):\\n        \\\"\\\"\\\"Test: d/dx((x虏, y虏)) = (2x, 2y).\\\"\\\"\\\"\\n        phi = PhiSymbol(self.x**2, self.y**2)\\n        \\n        result = self.phi_calc.differentiate_phi(phi, self.x)\\n        \\n        # Should distribute differentiation: (d/dx(x虏), d/dx(y虏)) = (2x, 0)\\n        self.assertIsInstance(result, PhiSymbol)\\n\\n\\nif __name__ == '__main__':\\n    unittest.main()\\n\""
        }
      ]
    },
    {
      "phase": 2,
      "name": "Symbolic Elevation and Differentiation",
      "objective": "Convert code to symbolic form and apply symbolic differentiation",
      "expected_impact": "Enables differentiation of larger code scopes than single operations",
      "duration_estimate": "2-3 weeks",
      "paper_reference": "Section 3, Figure 1",
      "tasks": [
        {
          "task_id": "2.1",
          "name": "Symbolic Elevation Engine",
          "file": "tangent/optimizations/symbolic_elevation.py",
          "description": "Convert AST/SSA to symbolic mathematical expressions",
          "code": "\"\"\"\\nSymbolic Elevation: Convert code to symbolic expressions.\\n\\nTakes SSA form (with -functions) and produces SymPy expressions.\\n\\\"\\\"\\\"\\n\\nimport ast\\nimport gast\\nimport sympy as sp\\nfrom typing import Dict, Any\\nfrom tangent.optimizations.phi_calculus import PhiSymbol, PhiCalculus\\n\\n\\nclass SymbolicElevator:\\n    \\\"\\\"\\\"\\n    Elevate code to symbolic form.\\n    \\n    Converts SSA IR with -functions to SymPy symbolic expressions.\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.var_to_symbol = {}  # var_name -> SymPy symbol\\n        self.phi_calc = PhiCalculus()\\n    \\n    def elevate_soi(self, soi_ast, active_inputs, active_outputs):\\n        \\\"\\\"\\\"\\n        Elevate Segment of Interest (SOI) to symbolic form.\\n        \\n        Args:\\n            soi_ast: AST of the code segment in SSA form\\n            active_inputs: Input variables (parameters)\\n            active_outputs: Output variables (what we're computing)\\n        \\n        Returns:\\n            Dict mapping output_var -> SymPy expression\\n        \\\"\\\"\\\"\\n        # Initialize symbols for inputs\\n        for var in active_inputs:\\n            self.var_to_symbol[var] = sp.Symbol(var)\\n        \\n        # Process each statement and build symbolic expressions\\n        for stmt in soi_ast.body:\\n            self._elevate_statement(stmt)\\n        \\n        # Return symbolic expressions for outputs\\n        output_exprs = {}\\n        for var in active_outputs:\\n            if var in self.var_to_symbol:\\n                output_exprs[var] = self.var_to_symbol[var]\\n        \\n        return output_exprs\\n    \\n    def _elevate_statement(self, stmt):\\n        \\\"\\\"\\\"Elevate a single statement to symbolic form.\\\"\\\"\\\"\\n        if isinstance(stmt, (ast.Assign, gast.Assign)):\\n            # Get LHS variable\\n            target = stmt.targets[0]\\n            if isinstance(target, (ast.Name, gast.Name)):\\n                var_name = target.id\\n                \\n                # Elevate RHS to symbolic expression\\n                rhs_expr = self._elevate_expression(stmt.value)\\n                \\n                # Store mapping\\n                self.var_to_symbol[var_name] = rhs_expr\\n    \\n    def _elevate_expression(self, expr):\\n        \\\"\\\"\\\"Elevate expression to SymPy.\\\"\\\"\\\"\\n        if isinstance(expr, (ast.Name, gast.Name)):\\n            var_name = expr.id\\n            if var_name in self.var_to_symbol:\\n                return self.var_to_symbol[var_name]\\n            else:\\n                # New variable, create symbol\\n                sym = sp.Symbol(var_name)\\n                self.var_to_symbol[var_name] = sym\\n                return sym\\n        \\n        elif isinstance(expr, (ast.Constant, gast.Constant)):\\n            return sp.Number(expr.value)\\n        \\n        elif isinstance(expr, (ast.Num, gast.Num)):\\n            return sp.Number(expr.n)\\n        \\n        elif isinstance(expr, (ast.BinOp, gast.BinOp)):\\n            left = self._elevate_expression(expr.left)\\n            right = self._elevate_expression(expr.right)\\n            \\n            op = expr.op\\n            if isinstance(op, (ast.Add, gast.Add)):\\n                return left + right\\n            elif isinstance(op, (ast.Sub, gast.Sub)):\\n                return left - right\\n            elif isinstance(op, (ast.Mult, gast.Mult)):\\n                return left * right\\n            elif isinstance(op, (ast.Div, gast.Div)):\\n                return left / right\\n            elif isinstance(op, (ast.Pow, gast.Pow)):\\n                return left ** right\\n        \\n        elif isinstance(expr, (ast.Call, gast.Call)):\\n            # Function call (sin, cos, exp, etc.)\\n            func_name = expr.func.id if isinstance(expr.func, (ast.Name, gast.Name)) else None\\n            \\n            if func_name:\\n                args = [self._elevate_expression(arg) for arg in expr.args]\\n                \\n                # Map to SymPy functions\\n                func_map = {\\n                    'sin': sp.sin,\\n                    'cos': sp.cos,\\n                    'tan': sp.tan,\\n                    'exp': sp.exp,\\n                    'log': sp.log,\\n                    'sqrt': sp.sqrt,\\n                }\\n                \\n                if func_name in func_map:\\n                    return func_map[func_name](*args)\\n                \\n                # Check if it's a -function\\n                if func_name.startswith('phi_'):\\n                    return PhiSymbol(*args)\\n        \\n        # Default: return None (unsupported)\\n        return None\\n\\n\\ndef elevate_to_symbolic(soi_ast, active_inputs, active_outputs):\\n    \\\"\\\"\\\"\\n    Elevate code segment to symbolic form.\\n    \\n    Args:\\n        soi_ast: Code segment in SSA form\\n        active_inputs: Input variables\\n        active_outputs: Output variables\\n    \\n    Returns:\\n        Dict: output_var -> SymPy expression\\n    \\\"\\\"\\\"\\n    elevator = SymbolicElevator()\\n    return elevator.elevate_soi(soi_ast, active_inputs, active_outputs)\\n\""
        },
        {
          "task_id": "2.2",
          "name": "Symbolic Differentiation Integration",
          "file": "tangent/optimizations/symbolic_differentiation.py",
          "description": "Apply symbolic differentiation to elevated expressions",
          "code": "\"\"\"\\nSymbolic differentiation for coarsened expressions.\\n\\nTakes symbolic expressions (from elevation) and differentiates them.\\n\\\"\\\"\\\"\\n\\nimport sympy as sp\\nfrom typing import Dict, List\\nfrom tangent.optimizations.phi_calculus import PhiCalculus, PhiSymbol\\n\\n\\nclass SymbolicDifferentiator:\\n    \\\"\\\"\\\"\\n    Symbolically differentiate expressions.\\n    \\n    Handles regular expressions and -expressions using -calculus.\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.phi_calc = PhiCalculus()\\n    \\n    def differentiate_soi(self, symbolic_exprs: Dict[str, sp.Expr], \\n                         wrt_vars: List[str]) -> Dict[str, Dict[str, sp.Expr]]:\\n        \\\"\\\"\\\"\\n        Differentiate symbolic expressions.\\n        \\n        Args:\\n            symbolic_exprs: Dict mapping output_var -> symbolic expression\\n            wrt_vars: Variables to differentiate with respect to\\n        \\n        Returns:\\n            Dict mapping output_var -> {wrt_var -> derivative expression}\\n        \\\"\\\"\\\"\\n        derivatives = {}\\n        \\n        for output_var, expr in symbolic_exprs.items():\\n            derivatives[output_var] = {}\\n            \\n            for wrt_var in wrt_vars:\\n                # Check if expression contains -functions\\n                if self._contains_phi(expr):\\n                    # Use -calculus differentiation\\n                    deriv = self._differentiate_phi_expression(expr, wrt_var)\\n                else:\\n                    # Standard SymPy differentiation\\n                    deriv = sp.diff(expr, wrt_var)\\n                \\n                derivatives[output_var][wrt_var] = deriv\\n        \\n        return derivatives\\n    \\n    def _contains_phi(self, expr):\\n        \\\"\\\"\\\"Check if expression contains -functions.\\\"\\\"\\\"\\n        if isinstance(expr, PhiSymbol):\\n            return True\\n        \\n        if hasattr(expr, 'args'):\\n            return any(self._contains_phi(arg) for arg in expr.args)\\n        \\n        return False\\n    \\n    def _differentiate_phi_expression(self, expr, wrt_var):\\n        \\\"\\\"\\\"\\n        Differentiate expression containing -functions.\\n        \\n        Uses distributive formula: d/dx((a,b)) = (d/dx(a), d/dx(b))\\n        \\\"\\\"\\\"\\n        if isinstance(expr, PhiSymbol):\\n            # Apply distributive formula\\n            return self.phi_calc.differentiate_phi(expr, sp.Symbol(wrt_var))\\n        \\n        # Recursively handle composite expressions\\n        if hasattr(expr, 'args'):\\n            # Differentiate using chain rule\\n            return sp.diff(expr, sp.Symbol(wrt_var))\\n        \\n        return sp.diff(expr, sp.Symbol(wrt_var))\\n\\n\\ndef differentiate_symbolic(symbolic_exprs, wrt_vars):\\n    \\\"\\\"\\\"\\n    Differentiate symbolic expressions.\\n    \\n    Args:\\n        symbolic_exprs: Dict of output_var -> expression\\n        wrt_vars: List of variables to differentiate w.r.t.\\n    \\n    Returns:\\n        Derivatives dict\\n    \\\"\\\"\\\"\\n    differentiator = SymbolicDifferentiator()\\n    return differentiator.differentiate_soi(symbolic_exprs, wrt_vars)\\n\""
        }
      ]
    },
    {
      "phase": 3,
      "name": "SOI Identification (Reuse-Aware)",
      "objective": "Identify optimal code segments for coarsening while preserving computation reuse",
      "expected_impact": "Balances coarsening scope vs reuse opportunities",
      "duration_estimate": "2 weeks",
      "paper_reference": "Section 5, Figure 7",
      "tasks": [
        {
          "task_id": "3.1",
          "name": "Reuse-Aware SOI Identification",
          "file": "tangent/optimizations/soi_identification.py",
          "description": "Implementation of Algorithm from Figure 7 in paper",
          "paper_reference": "Section 5, Figure 7",
          "code": "\"\"\"\\nSegment of Interest (SOI) Identification with reuse awareness.\\n\\nImplements the algorithm from Figure 7 of the paper.\\n\\\"\\\"\\\"\\n\\nimport ast\\nimport gast\\nfrom typing import List, Set, Dict\\nfrom collections import defaultdict\\n\\n\\nclass SOIIdentifier:\\n    \\\"\\\"\\\"\\n    Identify Segments of Interest for coarsening.\\n    \\n    Key challenge: Balance between:\\n    - Larger SOIs (more coarsening benefits)\\n    - Computation reuse (smaller SOIs can reuse intermediates)\\n    \\n    Algorithm from paper Figure 7 (a).\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self, max_soi_size=100):\\n        \\\"\\\"\\\"\\n        Args:\\n            max_soi_size: Upper limit for SOI size (avoid expression swell)\\n        \\\"\\\"\\\"\\n        self.max_soi_size = max_soi_size\\n        self.def_use_regions = None\\n    \\n    def identify_sois(self, func_ast, active_sinks: Set[str]) -> List['SOI']:\\n        \\\"\\\"\\\"\\n        Identify SOIs for a function (Algorithm from Figure 7a).\\n        \\n        Args:\\n            func_ast: Function in SSA form\\n            active_sinks: Output variables (active outputs)\\n        \\n        Returns:\\n            List of SOI objects\\n        \\\"\\\"\\\"\\n        sois = []\\n        \\n        # Step 1: For each active sink\\n        for sink in active_sinks:\\n            # Step 2: Get def-use chain\\n            def_use_chain = self._get_def_use_chain(func_ast, sink)\\n            \\n            # Step 3: Build def-use region tree (Figure 7b)\\n            region_tree = self._get_region_tree(def_use_chain)\\n            \\n            # Step 4: Traverse tree bottom-up (Figure 7c)\\n            worklist = self._get_bottom_up_order(region_tree)\\n            \\n            while worklist:\\n                node = worklist.pop(0)\\n                \\n                # Step 5: Check if node has large children\\n                if node.has_large_children():\\n                    node.mark_large()\\n                    node.merge_some_children()\\n                    # Add small children as SOIs\\n                    for child in node.children:\\n                        if not child.is_large():\\n                            sois.append(self._node_to_soi(child))\\n                    continue\\n                \\n                # Step 6: Get symbolic expression\\n                symbolic_expr = node.get_symbolic_expression()\\n                \\n                # Step 7: Check expression size\\n                if len(str(symbolic_expr)) > self.max_soi_size:\\n                    node.mark_large()\\n                    \\n                    # Step 8: If leaf, split on reuses\\n                    if node.is_leaf():\\n                        new_nodes = self._split_on_reuses(node)\\n                        worklist = new_nodes + worklist\\n                    \\n                else:\\n                    # Size OK, this node is an SOI\\n                    sois.append(self._node_to_soi(node))\\n        \\n        return sois\\n    \\n    def _get_def_use_chain(self, func_ast, var):\\n        \\\"\\\"\\\"\\n        Get def-use chain for a variable.\\n        \\n        Returns all definitions that lead to var's value.\\n        \\\"\\\"\\\"\\n        chain = []\\n        visited = set()\\n        worklist = [var]\\n        \\n        while worklist:\\n            current = worklist.pop()\\n            if current in visited:\\n                continue\\n            visited.add(current)\\n            \\n            # Find definition of current\\n            def_stmt = self._find_definition(func_ast, current)\\n            if def_stmt:\\n                chain.append(def_stmt)\\n                \\n                # Add variables used in definition\\n                used_vars = self._get_used_vars(def_stmt)\\n                worklist.extend(used_vars)\\n        \\n        return chain\\n    \\n    def _get_region_tree(self, def_use_chain):\\n        \\\"\\\"\\\"\\n        Build def-use region tree.\\n        \\n        Hierarchical structure with loop regions containing their bodies.\\n        \\\"\\\"\\\"\\n        # Build tree based on code region hierarchy\\n        root = RegionNode('root')\\n        \\n        # Group statements by their enclosing regions\\n        region_map = defaultdict(list)\\n        for stmt in def_use_chain:\\n            region = self._get_enclosing_region(stmt)\\n            region_map[region].append(stmt)\\n        \\n        # Build tree structure\\n        # (Simplified - would need proper hierarchy)\\n        for region, stmts in region_map.items():\\n            node = RegionNode(region)\\n            node.statements = stmts\\n            root.add_child(node)\\n        \\n        return root\\n    \\n    def _get_bottom_up_order(self, tree):\\n        \\\"\\\"\\\"Get nodes in bottom-up traversal order.\\\"\\\"\\\"\\n        order = []\\n        \\n        def traverse(node):\\n            for child in node.children:\\n                traverse(child)\\n            order.append(node)\\n        \\n        traverse(tree)\\n        return order\\n    \\n    def _split_on_reuses(self, node):\\n        \\\"\\\"\\\"\\n        Split node at variable with most reuses.\\n        \\n        Key heuristic from paper: When SOI too large, split at variable\\n        that is reused most (preserves important reuses).\\n        \\\"\\\"\\\"\\n        # Find variable with most uses\\n        var_uses = defaultdict(int)\\n        for stmt in node.statements:\\n            for var in self._get_used_vars(stmt):\\n                var_uses[var] += 1\\n        \\n        if not var_uses:\\n            return [node]\\n        \\n        # Split at most-used variable\\n        split_var = max(var_uses.items(), key=lambda x: x[1])[0]\\n        \\n        # Create two nodes: before and after split_var definition\\n        split_point = self._find_definition_index(node.statements, split_var)\\n        \\n        node1 = RegionNode(f'{node.name}_1')\\n        node1.statements = node.statements[:split_point+1]\\n        \\n        node2 = RegionNode(f'{node.name}_2')\\n        node2.statements = node.statements[split_point+1:]\\n        \\n        return [node1, node2]\\n    \\n    def _find_definition(self, func_ast, var):\\n        \\\"\\\"\\\"Find statement that defines variable.\\\"\\\"\\\"\\n        for stmt in ast.walk(func_ast):\\n            if isinstance(stmt, (ast.Assign, gast.Assign)):\\n                for target in stmt.targets:\\n                    if isinstance(target, (ast.Name, gast.Name)):\\n                        if target.id == var:\\n                            return stmt\\n        return None\\n    \\n    def _find_definition_index(self, stmts, var):\\n        \\\"\\\"\\\"Find index of statement defining variable.\\\"\\\"\\\"\\n        for i, stmt in enumerate(stmts):\\n            if isinstance(stmt, (ast.Assign, gast.Assign)):\\n                for target in stmt.targets:\\n                    if isinstance(target, (ast.Name, gast.Name)):\\n                        if target.id == var:\\n                            return i\\n        return -1\\n    \\n    def _get_used_vars(self, stmt):\\n        \\\"\\\"\\\"Get variables used in statement.\\\"\\\"\\\"\\n        used = []\\n        for node in ast.walk(stmt):\\n            if isinstance(node, (ast.Name, gast.Name)):\\n                if isinstance(node.ctx, (ast.Load, gast.Load)):\\n                    used.append(node.id)\\n        return used\\n    \\n    def _get_enclosing_region(self, stmt):\\n        \\\"\\\"\\\"Get enclosing region (loop/function) for statement.\\\"\\\"\\\"\\n        # Would need to track during AST traversal\\n        return 'default'\\n    \\n    def _node_to_soi(self, node):\\n        \\\"\\\"\\\"Convert region node to SOI.\\\"\\\"\\\"\\n        return SOI(node.name, node.statements)\\n\\n\\nclass RegionNode:\\n    \\\"\\\"\\\"Node in def-use region tree.\\\"\\\"\\\"\\n    \\n    def __init__(self, name):\\n        self.name = name\\n        self.children = []\\n        self.statements = []\\n        self.is_large_node = False\\n    \\n    def add_child(self, child):\\n        self.children.append(child)\\n    \\n    def has_large_children(self):\\n        return any(child.is_large_node for child in self.children)\\n    \\n    def mark_large(self):\\n        self.is_large_node = True\\n    \\n    def is_large(self):\\n        return self.is_large_node\\n    \\n    def is_leaf(self):\\n        return len(self.children) == 0\\n    \\n    def merge_some_children(self):\\n        \\\"\\\"\\\"Merge consecutive small children (up to size limit).\\\"\\\"\\\"\\n        # Implementation detail\\n        pass\\n    \\n    def get_symbolic_expression(self):\\n        \\\"\\\"\\\"Get symbolic expression for this node.\\\"\\\"\\\"\\n        # Would use symbolic elevation\\n        return str(self.statements)  # Placeholder\\n\\n\\nclass SOI:\\n    \\\"\\\"\\\"Segment of Interest - code segment for coarsening.\\\"\\\"\\\"\\n    \\n    def __init__(self, name, statements):\\n        self.name = name\\n        self.statements = statements\\n        self.active_inputs = set()\\n        self.active_outputs = set()\\n    \\n    def __repr__(self):\\n        return f'SOI({self.name}, {len(self.statements)} stmts)'\\n\\n\\ndef identify_sois(func_ast, active_outputs, max_soi_size=100):\\n    \\\"\\\"\\\"\\n    Identify SOIs for coarsening.\\n    \\n    Args:\\n        func_ast: Function AST in SSA form\\n        active_outputs: Output variables\\n        max_soi_size: Maximum SOI size (avoid expression swell)\\n    \\n    Returns:\\n        List of SOIs\\n    \\\"\\\"\\\"\\n    identifier = SOIIdentifier(max_soi_size)\\n    return identifier.identify_sois(func_ast, active_outputs)\\n\""
        }
      ]
    },
    {
      "phase": 4,
      "name": "Code Generation and Integration",
      "objective": "Generate optimized code from symbolic differentiation results and integrate into Tangent",
      "expected_impact": "Complete coarsening optimization pipeline",
      "duration_estimate": "2-3 weeks",
      "tasks": [
        {
          "task_id": "4.1",
          "name": "Code Generation from Symbolic Expressions",
          "file": "tangent/optimizations/code_generation.py",
          "description": "Generate Python code from differentiated symbolic expressions",
          "code": "\"\"\"\\nCode generation from symbolic expressions.\\n\\nConverts SymPy expressions (from symbolic differentiation) back to Python code.\\n\\\"\\\"\\\"\\n\\nimport ast\\nimport gast\\nimport sympy as sp\\nfrom sympy.printing.pycode import pycode\\nfrom typing import Dict\\n\\n\\nclass CodeGenerator:\\n    \\\"\\\"\\\"\\n    Generate Python code from symbolic expressions.\\n    \\n    Includes numerical stability transformations from paper Section 6.\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.stability_patterns = self._build_stability_patterns()\\n    \\n    def generate_gradient_function(self, \\n                                  derivatives: Dict[str, Dict[str, sp.Expr]],\\n                                  func_name: str) -> ast.FunctionDef:\\n        \\\"\\\"\\\"\\n        Generate gradient function from symbolic derivatives.\\n        \\n        Args:\\n            derivatives: Dict of output_var -> {wrt_var -> derivative_expr}\\n            func_name: Name for generated function\\n        \\n        Returns:\\n            AST of gradient function\\n        \\\"\\\"\\\"\\n        # Create function def\\n        func_def = gast.FunctionDef(\\n            name=func_name,\\n            args=self._create_args(derivatives),\\n            body=[],\\n            decorator_list=[],\\n            returns=None\\n        )\\n        \\n        # Generate body\\n        for output_var, output_derivs in derivatives.items():\\n            for wrt_var, deriv_expr in output_derivs.items():\\n                # Apply numerical stability transforms\\n                stable_expr = self._apply_stability(deriv_expr)\\n                \\n                # Generate code for this derivative\\n                deriv_stmt = self._generate_assignment(\\n                    f'd_{output_var}_d_{wrt_var}',\\n                    stable_expr\\n                )\\n                \\n                func_def.body.append(deriv_stmt)\\n        \\n        # Add return statement\\n        return_stmt = self._generate_return(derivatives)\\n        func_def.body.append(return_stmt)\\n        \\n        return func_def\\n    \\n    def _create_args(self, derivatives):\\n        \\\"\\\"\\\"Create function arguments.\\\"\\\"\\\"\\n        # Extract all variables involved\\n        vars_needed = set()\\n        for output_derivs in derivatives.values():\\n            for deriv_expr in output_derivs.values():\\n                vars_needed.update(str(s) for s in deriv_expr.free_symbols)\\n        \\n        # Create arg list\\n        args = gast.arguments(\\n            args=[gast.arg(arg=var, annotation=None) for var in sorted(vars_needed)],\\n            posonlyargs=[],\\n            kwonlyargs=[],\\n            kw_defaults=[],\\n            defaults=[]\\n        )\\n        \\n        return args\\n    \\n    def _generate_assignment(self, var_name, expr):\\n        \\\"\\\"\\\"Generate assignment statement from symbolic expression.\\\"\\\"\\\"\\n        # Convert SymPy to Python code string\\n        code_str = pycode(expr)\\n        \\n        # Parse to AST\\n        value_ast = ast.parse(code_str, mode='eval').body\\n        \\n        # Create assignment\\n        assign = gast.Assign(\\n            targets=[gast.Name(id=var_name, ctx=gast.Store())],\\n            value=value_ast\\n        )\\n        \\n        return assign\\n    \\n    def _generate_return(self, derivatives):\\n        \\\"\\\"\\\"Generate return statement.\\\"\\\"\\\"\\n        # Return dictionary of derivatives\\n        # Or tuple, depending on Tangent's convention\\n        \\n        return_vars = []\\n        for output_var, output_derivs in derivatives.items():\\n            for wrt_var in output_derivs:\\n                return_vars.append(f'd_{output_var}_d_{wrt_var}')\\n        \\n        if len(return_vars) == 1:\\n            # Single return value\\n            return gast.Return(value=gast.Name(id=return_vars[0], ctx=gast.Load()))\\n        else:\\n            # Multiple return values (tuple)\\n            return gast.Return(\\n                value=gast.Tuple(\\n                    elts=[gast.Name(id=var, ctx=gast.Load()) for var in return_vars],\\n                    ctx=gast.Load()\\n                )\\n            )\\n    \\n    def _build_stability_patterns(self):\\n        \\\"\\\"\\\"\\n        Build numerical stability patterns.\\n        \\n        From paper Section 6: log(1+e^x), softmax, etc.\\n        \\\"\\\"\\\"\\n        x = sp.Symbol('x')\\n        \\n        patterns = [\\n            {\\n                'pattern': sp.log(1 + sp.exp(x)),\\n                'stable': 'log1p_exp_stable(x)',  # Custom function\\n                'description': 'log(1 + e^x) overflow for large x'\\n            },\\n        ]\\n        \\n        return patterns\\n    \\n    def _apply_stability(self, expr):\\n        \\\"\\\"\\\"Apply numerical stability transformations.\\\"\\\"\\\"\\n        # Check each pattern\\n        for pattern_info in self.stability_patterns:\\n            # Try to match pattern\\n            # If match, replace with stable version\\n            pass\\n        \\n        return expr\\n\\n\\ndef generate_code(derivatives, func_name='grad_coarsened'):\\n    \\\"\\\"\\\"\\n    Generate code from symbolic derivatives.\\n    \\n    Args:\\n        derivatives: Symbolic derivatives\\n        func_name: Name for generated function\\n    \\n    Returns:\\n        Function AST\\n    \\\"\\\"\\\"\\n    generator = CodeGenerator()\\n    return generator.generate_gradient_function(derivatives, func_name)\\n\""
        },
        {
          "task_id": "4.2",
          "name": "Integration with Tangent AD",
          "file": "tangent/optimizations/coarsening.py",
          "description": "Main coarsening entry point integrating all components",
          "code": "\"\"\"\\nCoarsening Optimization - Main Entry Point.\\n\\nIntegrates all components: SSA, -calculus, symbolic elevation,\\ndifferentiation, SOI identification, and code generation.\\n\\\"\\\"\\\"\\n\\nimport ast\\nimport gast\\nfrom typing import List, Set\\n\\nfrom tangent.optimizations.ssa import convert_to_ssa\\nfrom tangent.optimizations.soi_identification import identify_sois\\nfrom tangent.optimizations.symbolic_elevation import elevate_to_symbolic\\nfrom tangent.optimizations.symbolic_differentiation import differentiate_symbolic\\nfrom tangent.optimizations.code_generation import generate_code\\n\\n\\nclass CoarseningOptimizer:\\n    \\\"\\\"\\\"\\n    Main coarsening optimizer.\\n    \\n    Pipeline:\\n    1. Convert to SSA\\n    2. Identify SOIs\\n    3. Elevate SOIs to symbolic form\\n    4. Symbolically differentiate\\n    5. Generate optimized code\\n    6. Integrate with AD\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self, max_soi_size=100):\\n        self.max_soi_size = max_soi_size\\n        self.stats = {}\\n    \\n    def optimize(self, func_ast, wrt_vars: List[str]):\\n        \\\"\\\"\\\"\\n        Apply coarsening optimization.\\n        \\n        Args:\\n            func_ast: Function AST (primal computation)\\n            wrt_vars: Variables to differentiate w.r.t.\\n        \\n        Returns:\\n            Optimized gradient function AST\\n        \\\"\\\"\\\"\\n        # Step 1: Convert to SSA\\n        ssa_func = convert_to_ssa(func_ast)\\n        \\n        # Step 2: Identify active outputs (return values)\\n        active_outputs = self._find_active_outputs(func_ast)\\n        \\n        # Step 3: Identify SOIs\\n        sois = identify_sois(ssa_func, active_outputs, self.max_soi_size)\\n        self.stats['num_sois'] = len(sois)\\n        \\n        # Step 4: Process each SOI\\n        coarsened_gradients = []\\n        \\n        for soi in sois:\\n            # Step 4a: Elevate to symbolic\\n            symbolic_exprs = elevate_to_symbolic(\\n                soi.statements,\\n                soi.active_inputs,\\n                soi.active_outputs\\n            )\\n            \\n            # Step 4b: Symbolically differentiate\\n            derivatives = differentiate_symbolic(symbolic_exprs, wrt_vars)\\n            \\n            # Step 4c: Generate code\\n            grad_func = generate_code(derivatives, f'grad_{soi.name}')\\n            \\n            coarsened_gradients.append(grad_func)\\n        \\n        # Step 5: Integrate coarsened gradients with AD\\n        optimized_grad = self._integrate_with_ad(\\n            func_ast,\\n            coarsened_gradients,\\n            sois,\\n            wrt_vars\\n        )\\n        \\n        return optimized_grad\\n    \\n    def _find_active_outputs(self, func_ast):\\n        \\\"\\\"\\\"Find output variables (return values).\\\"\\\"\\\"\\n        outputs = set()\\n        \\n        for node in ast.walk(func_ast):\\n            if isinstance(node, (ast.Return, gast.Return)):\\n                if node.value:\\n                    # Extract variable names from return\\n                    if isinstance(node.value, (ast.Name, gast.Name)):\\n                        outputs.add(node.value.id)\\n                    elif isinstance(node.value, (ast.Tuple, gast.Tuple)):\\n                        for elt in node.value.elts:\\n                            if isinstance(elt, (ast.Name, gast.Name)):\\n                                outputs.add(elt.id)\\n        \\n        return outputs\\n    \\n    def _integrate_with_ad(self, func_ast, coarsened_gradients, sois, wrt_vars):\\n        \\\"\\\"\\\"\\n        Integrate coarsened gradients with AD.\\n        \\n        Strategy:\\n        - Coarsened SOIs provide shortcuts\\n        - Remaining computations use AD\\n        - Connect via chain rule\\n        \\\"\\\"\\\"\\n        # Create hybrid gradient function\\n        hybrid_grad = gast.FunctionDef(\\n            name=f'{func_ast.name}_grad_coarsened',\\n            args=func_ast.args,\\n            body=[],\\n            decorator_list=[],\\n            returns=None\\n        )\\n        \\n        # Add coarsened gradient calls\\n        for i, (grad_func, soi) in enumerate(zip(coarsened_gradients, sois)):\\n            # Call coarsened gradient for this SOI\\n            call = self._create_gradient_call(grad_func, soi)\\n            hybrid_grad.body.append(call)\\n        \\n        # Add AD for remaining parts\\n        ad_calls = self._generate_ad_calls(func_ast, sois, wrt_vars)\\n        hybrid_grad.body.extend(ad_calls)\\n        \\n        # Combine results via chain rule\\n        chain_rule_code = self._generate_chain_rule_combination(sois, wrt_vars)\\n        hybrid_grad.body.extend(chain_rule_code)\\n        \\n        return hybrid_grad\\n    \\n    def _create_gradient_call(self, grad_func, soi):\\n        \\\"\\\"\\\"Create call to coarsened gradient function.\\\"\\\"\\\"\\n        # This would create AST for calling grad_func\\n        # Placeholder\\n        return gast.Pass()\\n    \\n    def _generate_ad_calls(self, func_ast, sois, wrt_vars):\\n        \\\"\\\"\\\"Generate AD calls for non-coarsened parts.\\\"\\\"\\\"\\n        # For parts not covered by SOIs, use default AD\\n        # Placeholder\\n        return []\\n    \\n    def _generate_chain_rule_combination(self, sois, wrt_vars):\\n        \\\"\\\"\\\"Generate chain rule to combine SOI gradients.\\\"\\\"\\\"\\n        # Combine partial derivatives via chain rule\\n        # Placeholder\\n        return []\\n\\n\\ndef apply_coarsening(func_ast, wrt_vars, config=None):\\n    \\\"\\\"\\\"\\n    Apply coarsening optimization.\\n    \\n    Args:\\n        func_ast: Function to optimize\\n        wrt_vars: Variables to differentiate w.r.t.\\n        config: Configuration dict\\n    \\n    Returns:\\n        Optimized gradient function AST and statistics\\n    \\\"\\\"\\\"\\n    config = config or {}\\n    max_soi_size = config.get('max_soi_size', 100)\\n    \\n    optimizer = CoarseningOptimizer(max_soi_size)\\n    optimized = optimizer.optimize(func_ast, wrt_vars)\\n    \\n    return optimized, optimizer.stats\\n\""
        },
        {
          "task_id": "4.3",
          "name": "Coarsening Benchmarks (from Paper)",
          "file": "tests/benchmarks/coarsening_benchmarks.py",
          "description": "Reproduce benchmarks from paper: CartPole, BGDHyperOpt, etc.",
          "code": "\"\"\"\\nCoarsening benchmarks matching those in the paper.\\n\\nTests from Table 3 of paper.\\n\\\"\\\"\\\"\\nimport time\\nimport json\\nimport math\\n\\n\\nclass CartPoleBenchmark:\\n    \\\"\\\"\\\"\\n    CartPole benchmark from paper Section 3.\\n    \\n    Expected speedup: 1.05-1.12 (from paper Table 3)\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.name = 'CartPole'\\n    \\n    def setup(self):\\n        # Simplified CartPole physics\\n        def update_state_baseline(x, a):\\n            # Without coarsening - operation by operation AD\\n            rt = 9*a + 0.045*x[3]*x[3]*math.sin(x[2])\\n            qt = (9.8*math.sin(x[2]) - rt*math.cos(x[2])) / (0.65 - 0.4*math.cos(x[2])**2)\\n            pt = rt - 0.045*qt*math.cos(x[2])\\n            \\n            x_new = [\\n                x[0] + 0.02*x[1],\\n                x[1] + 0.02*pt,\\n                x[2] + 0.02*x[3],\\n                x[3] + 0.02*qt\\n            ]\\n            return x_new\\n        \\n        # With coarsening - symbolic differentiation of entire update\\n        def update_state_coarsened(x, a):\\n            # Coarsened version (would be generated by optimization)\\n            # Pre-computed closed forms\\n            cos_x2 = math.cos(x[2])\\n            cos2_x2 = cos_x2 * cos_x2  # CSE\\n            \\n            rt = 9*a + 0.045*x[3]*x[3]*math.sin(x[2])\\n            qt = (9.8*math.sin(x[2]) - rt*cos_x2) / (0.65 - 0.4*cos2_x2)\\n            pt = rt - 0.045*qt*cos_x2\\n            \\n            x_new = [\\n                x[0] + 0.02*x[1],\\n                x[1] + 0.02*pt,\\n                x[2] + 0.02*x[3],\\n                x[3] + 0.02*qt\\n            ]\\n            return x_new\\n        \\n        self.baseline = update_state_baseline\\n        self.coarsened = update_state_coarsened\\n        self.state = [0.0, 0.0, 0.1, 0.0]\\n        self.action = 1.0\\n    \\n    def run(self, iterations=10000):\\n        # Baseline\\n        start = time.perf_counter()\\n        for _ in range(iterations):\\n            self.baseline(self.state, self.action)\\n        baseline_time = (time.perf_counter() - start) / iterations\\n        \\n        # Coarsened\\n        start = time.perf_counter()\\n        for _ in range(iterations):\\n            self.coarsened(self.state, self.action)\\n        coarsened_time = (time.perf_counter() - start) / iterations\\n        \\n        return {\\n            'baseline_time': baseline_time * 1000,\\n            'coarsened_time': coarsened_time * 1000,\\n            'speedup': baseline_time / coarsened_time\\n        }\\n\\n\\nclass BGDHyperOptBenchmark:\\n    \\\"\\\"\\\"\\n    BGDHyperOpt from paper Section 7, Figure 6.\\n    \\n    Expected speedup: 23-27 (from paper Table 3)\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.name = 'BGDHyperOpt'\\n    \\n    def setup(self, n_data=200):\\n        # Generate synthetic data\\n        import random\\n        self.x = [random.random() * 10 for _ in range(n_data)]\\n        self.y = [2*x + 1 + random.random() for x in self.x]\\n        self.n = n_data\\n        \\n        # Baseline: gradient computed operation-by-operation\\n        def compute_gradient_baseline(x_data, y_data, w, r):\\n            n = len(x_data)\\n            gradient = 0.0\\n            \\n            # Multiple passes, lots of overhead\\n            for i in range(n):\\n                gradient += 2 * x_data[i] * (y_data[i] - x_data[i] * w)\\n            \\n            gradient = gradient / n\\n            return gradient\\n        \\n        # Coarsened: symbolic differentiation of entire gradient\\n        def compute_gradient_coarsened(x_data, y_data, w, r):\\n            # Closed form from coarsening (from paper Figure 6)\\n            n = len(x_data)\\n            \\n            sum_xy = sum(x*y for x, y in zip(x_data, y_data))\\n            sum_x2 = sum(x*x for x in x_data)\\n            \\n            # Closed form gradient\\n            gradient = (2*sum_xy - 2*sum_x2*w) / n\\n            return gradient\\n        \\n        self.baseline = compute_gradient_baseline\\n        self.coarsened = compute_gradient_coarsened\\n        self.w = 1.5\\n        self.r = 0.01\\n    \\n    def run(self, iterations=1000):\\n        # Baseline\\n        start = time.perf_counter()\\n        for _ in range(iterations):\\n            self.baseline(self.x, self.y, self.w, self.r)\\n        baseline_time = (time.perf_counter() - start) / iterations\\n        \\n        # Coarsened\\n        start = time.perf_counter()\\n        for _ in range(iterations):\\n            self.coarsened(self.x, self.y, self.w, self.r)\\n        coarsened_time = (time.perf_counter() - start) / iterations\\n        \\n        return {\\n            'baseline_time': baseline_time * 1000,\\n            'coarsened_time': coarsened_time * 1000,\\n            'speedup': baseline_time / coarsened_time\\n        }\\n\\n\\ndef run_coarsening_benchmarks():\\n    \\\"\\\"\\\"Run all coarsening benchmarks from paper.\\\"\\\"\\\"\\n    benchmarks = [\\n        CartPoleBenchmark(),\\n        BGDHyperOptBenchmark(),\\n    ]\\n    \\n    print(\\\"=\\\" * 80)\\n    print(\\\"COARSENING OPTIMIZATION BENCHMARKS (from paper)\\\")\\n    print(\\\"=\\\" * 80)\\n    print()\\n    \\n    results = {}\\n    \\n    for bench in benchmarks:\\n        print(f\\\"Running: {bench.name}\\\")\\n        bench.setup()\\n        result = bench.run()\\n        results[bench.name] = result\\n        \\n        print(f\\\"  Baseline:  {result['baseline_time']:.3f} ms\\\")\\n        print(f\\\"  Coarsened: {result['coarsened_time']:.3f} ms\\\")\\n        print(f\\\"  Speedup:   {result['speedup']:.2f}\\\")\\n        print()\\n    \\n    # Save results\\n    with open('coarsening_benchmark_results.json', 'w') as f:\\n        json.dump(results, f, indent=2)\\n    \\n    return results\\n\\n\\nif __name__ == '__main__':\\n    run_coarsening_benchmarks()\\n\""
        }
      ]
    }
  ],
  "success_criteria": {
    "correctness": [
      "-calculus formulae match paper specifications",
      "Symbolic differentiation produces correct gradients",
      "Generated code produces numerically equivalent results to AD",
      "Handles loops, conditionals, and complex control flow"
    ],
    "performance": [
      "CartPole: 1.05-1.12 speedup (match paper)",
      "BGDHyperOpt: 23-27 speedup (match paper)",
      "Overall: 2-27 speedup range depending on code structure",
      "Memory: 40-70% reduction (fewer intermediate allocations)"
    ],
    "usability": [
      "Automatic SOI identification (no manual annotation)",
      "Graceful fallback to AD if coarsening fails",
      "Clear error messages and warnings",
      "Integration with existing Tangent API"
    ]
  },
  "integration_with_tangent": {
    "entry_point": "tangent/grad.py",
    "modification": "Add coarsening as optimization pass before/after DCE",
    "usage": "grad_f = tangent.grad(f, wrt=['x'], optimizations={'coarsening': True})",
    "fallback": "If coarsening fails, fall back to standard AD"
  },
  "final_deliverables": {
    "code_files": [
      "tangent/optimizations/ssa.py",
      "tangent/optimizations/phi_calculus.py",
      "tangent/optimizations/symbolic_elevation.py",
      "tangent/optimizations/symbolic_differentiation.py",
      "tangent/optimizations/soi_identification.py",
      "tangent/optimizations/code_generation.py",
      "tangent/optimizations/coarsening.py",
      "tests/test_phi_calculus.py",
      "tests/test_coarsening.py",
      "tests/benchmarks/coarsening_benchmarks.py"
    ],
    "documentation": [
      "docs/COARSENING.md - User guide",
      "docs/PHI_CALCULUS.md - -calculus explanation",
      "docs/COARSENING_IMPLEMENTATION.md - Implementation details"
    ]
  },
  "timeline": {
    "phase_1": "3-4 weeks (-calculus foundation)",
    "phase_2": "2-3 weeks (symbolic elevation & differentiation)",
    "phase_3": "2 weeks (SOI identification)",
    "phase_4": "2-3 weeks (code generation & integration)",
    "total": "9-12 weeks"
  },
  "notes": {
    "complexity": "High - novel research contribution requiring careful implementation",
    "key_insight": "-calculus is the breakthrough that makes coarsening work across control flow",
    "most_complex_part": "-calculus implementation and SOI identification",
    "testing_strategy": "Extensive testing against paper's benchmarks to validate correctness and performance",
    "numerical_stability": "Critical - implement stability transforms from paper Section 6"
  }
}